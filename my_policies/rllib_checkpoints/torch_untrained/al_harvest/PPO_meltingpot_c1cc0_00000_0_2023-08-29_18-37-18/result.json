{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"agent_13": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.159790655761435, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.9240227389231063, "policy_loss": -0.03683155137195922, "vf_loss": 0.9456187881758077, "vf_explained_var": 0.14105916002340485, "kl": 0.07617752962722918, "entropy": 2.3531590357161405, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_2": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5237149716207856, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.571211058590888, "policy_loss": -0.00658992680541256, "vf_loss": 2.57748230712717, "vf_explained_var": -0.03361095346902546, "kl": 0.0015934180603436655, "entropy": 2.3976788976736234, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_8": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5749164675019289, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.00830598940517296, "policy_loss": -0.08052997598914724, "vf_loss": 0.07511064716856165, "vf_explained_var": -0.23018031078472473, "kl": 0.06862660186294954, "entropy": 2.397120641825492, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_7": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7990534668167432, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.12260704241823732, "policy_loss": -0.009670835772627279, "vf_loss": 0.13024238219616308, "vf_explained_var": -0.6993368200042791, "kl": 0.010177479126647489, "entropy": 2.397861537180449, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_4": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.091469714816725, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 6.29851886184494, "policy_loss": 0.08121060881959764, "vf_loss": 6.205632753330365, "vf_explained_var": -0.1978701981536129, "kl": 0.05837755928908907, "entropy": 2.3514893172080056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_14": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.621803460779943, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.4051687984694645, "policy_loss": 0.02026801975934129, "vf_loss": 0.36471688766931104, "vf_explained_var": 0.374436491727829, "kl": 0.10091945066197382, "entropy": 2.363391511482105, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_9": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.4482411673978755, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.04697223849463881, "policy_loss": 0.04100796560707845, "vf_loss": 0.004996338085370473, "vf_explained_var": -1.0, "kl": 0.0048396770548169285, "entropy": 2.3934030997125726, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_5": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 10.509204876475167, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 4.643770713061748, "policy_loss": -0.03470904994429203, "vf_loss": 4.675261051978981, "vf_explained_var": -0.31612764931561654, "kl": 0.01609352645179471, "entropy": 2.3441061488369055, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_6": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.9525412919228538, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": -0.01832359181880428, "policy_loss": -0.020797258288713923, "vf_loss": 0.0014753614591814165, "vf_explained_var": -1.0, "kl": 0.00499152605919689, "entropy": 2.3947710735756056, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_3": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.0251971965296227, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.34211959826286165, "policy_loss": -0.02228271609597039, "vf_loss": 0.3476485999793573, "vf_explained_var": -0.025242036999317638, "kl": 0.08376855669518846, "entropy": 2.3212547666148136, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_15": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.9525789808808711, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 2.0248359220935717, "policy_loss": -0.007399370403666245, "vf_loss": 2.03180572823172, "vf_explained_var": -0.6930093559256771, "kl": 0.002147906067503493, "entropy": 2.396873085958916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_1": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 5.444296343441595, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 4.898880403972509, "policy_loss": 0.05363247331166476, "vf_loss": 4.8366206271606575, "vf_explained_var": 0.06941484139676679, "kl": 0.043136382052318935, "entropy": 2.393989401951171, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_10": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 24.849369196724474, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.22137109097420124, "policy_loss": 0.006742971586553674, "vf_loss": 0.21062344683562978, "vf_explained_var": 0.24420112977948105, "kl": 0.020023384142033814, "entropy": 2.313067332903544, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_12": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.7190085543286906, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 9.109652869743213, "policy_loss": 0.07496769924958548, "vf_loss": 9.034507588866951, "vf_explained_var": -0.043883750313206724, "kl": 0.0008880518164299323, "entropy": 2.3971265198891625, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_11": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.7058460431140765, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": -0.0874406272120643, "policy_loss": -0.09872184091231279, "vf_loss": 0.009088606537848695, "vf_explained_var": -0.8615534419553321, "kl": 0.01096303462287809, "entropy": 2.3892899023859124, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}, "agent_0": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.5495318895369246, "cur_kl_coeff": 0.19999999999999998, "cur_lr": 5.000000000000001e-05, "total_loss": 0.6936046760594635, "policy_loss": -0.05846626957911148, "vf_loss": 0.7514832833814516, "vf_explained_var": 0.4669090921418709, "kl": 0.0029383069262954625, "entropy": 2.397871544904876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 32.0, "num_grad_updates_lifetime": 285.5, "diff_num_grad_updates_vs_sampler_policy": 284.5}}, "num_env_steps_sampled": 400, "num_env_steps_trained": 400, "num_agent_steps_sampled": 6400, "num_agent_steps_trained": 6400}, "sampler_results": {"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}}, "episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "num_faulty_episodes": 0, "connector_metrics": {}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 6400, "num_agent_steps_trained": 6400, "num_env_steps_sampled": 400, "num_env_steps_trained": 400, "num_env_steps_sampled_this_iter": 400, "num_env_steps_trained_this_iter": 400, "num_env_steps_sampled_throughput_per_sec": 2.5165572809834997, "num_env_steps_trained_throughput_per_sec": 2.5165572809834997, "timesteps_total": 400, "num_steps_trained_this_iter": 400, "agent_timesteps_total": 6400, "timers": {"training_iteration_time_ms": 158947.256, "sample_time_ms": 26272.806, "learn_time_ms": 132617.941, "learn_throughput": 3.016, "synch_weights_time_ms": 53.644}, "counters": {"num_env_steps_sampled": 400, "num_env_steps_trained": 400, "num_agent_steps_sampled": 6400, "num_agent_steps_trained": 6400}, "done": true, "episodes_total": 0, "training_iteration": 1, "trial_id": "c1cc0_00000", "date": "2023-08-29_18-40-22", "timestamp": 1693359622, "time_this_iter_s": 158.99594712257385, "time_total_s": 158.99594712257385, "pid": 23877, "hostname": "Rakshits-MacBook-Pro.local", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "aot_eager", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "aot_eager", "torch_compile_worker_dynamo_mode": null, "env": "meltingpot", "env_config": {"substrate": "allelopathic_harvest__open", "roles": ["player_who_likes_red", "player_who_likes_red", "player_who_likes_red", "player_who_likes_red", "player_who_likes_red", "player_who_likes_red", "player_who_likes_red", "player_who_likes_red", "player_who_likes_green", "player_who_likes_green", "player_who_likes_green", "player_who_likes_green", "player_who_likes_green", "player_who_likes_green", "player_who_likes_green", "player_who_likes_green"], "scaled": 8}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "_is_atari": null, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": "auto", "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": null, "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 5e-05, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 400, "model": {"_disable_preprocessor_api": true, "_disable_action_flattening": false, "fcnet_hiddens": [4, 4], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [16], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": true, "max_seq_len": 20, "lstm_cell_size": 2, "lstm_use_prev_action": true, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function get_experiment_config.<locals>.<lambda> at 0x7fa303387640>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "INFO", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": null, "_enable_rl_module_api": false, "_AlgorithmConfig__prior_exploration_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": true, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 32, "num_sgd_iter": 30, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"agent_0": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_1": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_2": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_3": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_4": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_5": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_6": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_7": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_8": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_9": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_10": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_11": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_12": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_13": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_14": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}], "agent_15": [null, "Dict('COLLECTIVE_REWARD': Box(-inf, inf, (), float64), 'READY_TO_SHOOT': Box(-inf, inf, (), float64), 'RGB': Box(0, 255, (11, 11, 3), uint8))", "Discrete(11)", {"model": {"conv_filters": [[16, [8, 8], 1], [128, [11, 11], 1]]}}]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 158.99594712257385, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 15.513656387665199, "ram_util_percent": 65.05330396475772}}
